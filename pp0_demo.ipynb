{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.layers import Input,Conv1D,MaxPool1D,LSTM,Flatten,Dropout,Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm(input_vector, output_size=20, filters=256, strides=3, pool_size=4, units=32, dropout=0.7, lr=0.001)->tf.keras.Model:\n",
    "    inp = Input((input_vector, 1))\n",
    "    x = Conv1D( filters, kernel_size=16, strides=strides, activation='relu')(inp)\n",
    "    x = MaxPool1D(pool_size=pool_size, padding='same')(x)\n",
    "    x = Conv1D(filters, kernel_size=8, strides=strides, activation='relu', padding='same')(x)\n",
    "    x = MaxPool1D(pool_size=pool_size, padding='same')(x)\n",
    "    x = LSTM(units, return_sequences=True, recurrent_activation='hard_sigmoid')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    preds = Dense(output_size, activation='softmax')(x)\n",
    "    model = Model(inputs=inp, outputs=preds)\n",
    "    opt = tf.keras.optimizers.Adam(lr)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])  # optimizer, metrics\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_cnn_lstm(input_vector, output_size=20, filters=256, strides=3, pool_size=4, units=32, dropout=0.7, kernel_size=32, lr=0.001):\n",
    "    inp = Input((input_vector, 1))\n",
    "    x = Conv1D(filters, kernel_size=kernel_size, strides=strides, activation='relu')(inp)\n",
    "    x = MaxPool1D(pool_size=pool_size, padding='same')(x)\n",
    "    x = LSTM(units, return_sequences=True, recurrent_activation='hard_sigmoid')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    preds = Dense(output_size, activation='softmax')(x)\n",
    "    model = Model(inputs=inp, outputs=preds)\n",
    "    opt = tf.keras.optimizers.Adam(lr)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])  # optimizer, metrics\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_occupancy_data='default_small.npz'\n",
    "sweeps_data='sweeps_small.npz'\n",
    "sns_data='sns_small.npz'\n",
    "dns_data='dns_small.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=sweeps_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(path)\n",
    "X=np.array( data['X'],dtype=np.float32)\n",
    "X=X.reshape(*X.shape,-1)\n",
    "y=np.array( data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc=LabelEncoder()\n",
    "lab_hot=OneHotEncoder()\n",
    "y_num= lab_enc.fit_transform(y)\n",
    "y_hot=lab_hot.fit_transform(y_num.reshape(-1,1))\n",
    "y_hot=y_hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1620 samples, validate on 180 samples\n",
      "Epoch 1/5\n",
      "1620/1620 - 3s - loss: 2.9108 - accuracy: 0.1105 - val_loss: 2.6085 - val_accuracy: 0.2444\n",
      "Epoch 2/5\n",
      "1620/1620 - 2s - loss: 2.3390 - accuracy: 0.2821 - val_loss: 1.6957 - val_accuracy: 0.5222\n",
      "Epoch 3/5\n",
      "1620/1620 - 2s - loss: 1.5724 - accuracy: 0.4994 - val_loss: 1.0779 - val_accuracy: 0.6944\n",
      "Epoch 4/5\n",
      "1620/1620 - 2s - loss: 1.0661 - accuracy: 0.6660 - val_loss: 0.6877 - val_accuracy: 0.8389\n",
      "Epoch 5/5\n",
      "1620/1620 - 2s - loss: 0.7217 - accuracy: 0.7852 - val_loss: 0.4774 - val_accuracy: 0.8833\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedShuffleSplit(n_splits=10,random_state=666)\n",
    "preds=[]\n",
    "true=[]\n",
    "for train_index, test_index in skf.split(X, y_num):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    mean=X_train.mean()\n",
    "    std=X_train.std()\n",
    "    X_train_norm=(X_train-mean+1e-10)/std\n",
    "    X_test_norm=(X_test-mean+1e-10)/std\n",
    "\n",
    "    y_train, y_test = y_hot[train_index], y_num[test_index]\n",
    "    length=X_train.shape[1]\n",
    "    if length<1000:\n",
    "        model=small_cnn_lstm(X_train.shape[1])\n",
    "    else:\n",
    "        model=cnn_lstm(X_train.shape[1])\n",
    "    model.fit(X_train_norm,y_train,validation_split=0.1,epochs=5,verbose=2,callbacks=[EarlyStopping( patience=5,restore_best_weights=True)])\n",
    "    preds.extend( model.predict(X_test_norm).argmax(axis=-1))\n",
    "    true.extend(y_test)\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds==true)/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv2",
   "language": "python",
   "name": "tfenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
